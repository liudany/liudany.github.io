---
layout: post
title: FastText for text classification
date: 2018-07-23 09:28:09
tags: [NLP, Text Classification]
categories: [NLP]

---

7/23

老板让在系统之前加一个目标分类的过程，想通过这个提升一下针对性和准确率。

今天看了下相关方面的综述，日常产生了一种「说不定能在这个领域做出点东西」的错觉。总的来说TextClassification模型分五类：

1. 词嵌入向量化
2. 基于CNN
3. 基于RNN及各种变体
4. Attention机制
5. 记忆存储机制

可以看到基本的框架结构和其他深度学习方面都是差不多的，好像所有文本任务的发展都是**RNN -> CNN -> Attention**这个方向发展的。

7/24

今天搞搞fastText。

# fastText

## Introduction

Facebook团队做的一个词嵌入和句子分类的工具包。其中有不少看起来很有用的东西：

- 目前state-of-the-art的英文词向量。
- 根据Wiki和爬来的一些数据训练的157种训练好的词向量。
- 用于语言识别的模型，和一些有监督任务（指TextClassification）的模型。

数据集来自YFCC100M，即Yahoo Flickr Creative Commons 100 Million，还挺唬人的。

总结了一些有用的[cheatsheet](https://fasttext.cc/docs/en/cheatsheet.html#content) ，算是快速上手帮助。

这个项目是用PyThon写的，没有使用PyTorch（？）。

## 安装

推荐使用make方法来装，也有cmake和Python方法。

## 使用

### Word Vectors
### Text Classification
#### 语料预处理

首先下载数据集，官方的tutorial提供了一个关于[食物的数据集](https://s3-us-west-1.amazonaws.com/fasttext-vectors/cooking.stackexchange.tar.gz)，需要翻墙下载。其中数据格式形为：
```
__label__sauce __label__cheese How much does potato starch affect a cheese sauce recipe?
__label__food-safety __label__acidity Dangerous pathogens capable of growing in acidic environments
__label__cast-iron __label__stove How do I cover up the white spots on my cast iron stove?
```

每个句子的分类由前面的`__label__xxx`来决定，每个句子可以有多个标签，由空格分开。

然后用`tail -n`和`head -n`命令来划分训练集和测试集：
```
head -n 12404 cooking.stackexchange.txt > cooking.train
tail -n 3000 cooking.stackexchange.txt > cooking.train
```

`head`和`tail`命令本身用于查看，`-n`参数表示行数，箭头用来将输出生成到文件。


#### 训练和验证
```shell
$ ./fasttext supervised -input train.txt -output model
```

其中`train.txt`是训练集句子的文件，其中每行是一个句子和它的标签。其中，表示标签的词汇是以字符串`__label__`为前缀的。输出为两个文件：`model.bin`和`model.vec`。

模型训练完毕之后，在测试集上验证准确率：
```shell
$ ./fasttext test model.bin test.txt k
```

参数`k`是可选的，默认为1。

为了获得一个文本对应的k个最可能的标签，使用：
```shell
$ ./fasttext predict model.bin test.txt k
```

或者使用`predict-prob`来获得某种标签对应的概率：
```shell
$ ./fasttext predict-prob model.bin test.txt k
```

其中`test.txt`中每行为一个待分类的句子。执行上面语句将会在每行输出句子对应的k个最可能的标签。

每次的输出中有`P@1`和`R@1`，分别为准确率和召回率。准确率是指，模型所预测出的标签中有几个是正确的；召回率是指，原项目的正确标签中有几个被正确预测出来。

#### 提高准确率

去除标点符号，和进行大小写的转换：
```
cat cooking.stackexchange.txt | sed -e "s/\([.\!?,'/()]\)/ \1 /g" | tr "[:upper:]" "[:lower:]" > cooking.preprocessed.txt
```
其中，`|`分割的命令，将前面的输出作为后面的输入；`sed`是强大的文本流处理工具，主要用正则匹配，这里用其曲调标点符号；`tr`命令也是用于文本的替换和压缩，这里用其统一大小写；最后再进行训练和验证集合的划分等操作。

`-lr`和`-epoch`参数用于指定学习率和训练的轮数。`-wordNgrams`用于使用Ngram方法来训练分类器。`-loss hs`开启使用hierarchical softmax，大大提高训练的速度，但是会损失一些准确率。

## 原理

是一篇ACL的短文。