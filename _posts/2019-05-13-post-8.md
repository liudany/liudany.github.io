---
layout: post
title: About Autoencoder
date: 2019-05-13 09:28:09
tags: [Autoencoder]
categories: [Autoencoder]
typora-root-url: ../../static
---

毕业论文就定了这个方向吧，从[台大李宏毅老师的课程](https://www.youtube.com/watch?v=Tk5B4seA-AU&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&index=25)入门一下。

# PCA

![](/img/pca.png)

是一种线性的降维方法，Symmetric。

# Auto-encoder

Symmetric is not necessary，是Unsupervised的，Hinton论文中一般会先把features维度先扩大，再压缩。

## Text retrieval

文本检索，查询词汇query和每篇文章的表示做dot product/cosine similarity计算，然后retrieve距离最近的文章。以前是用Bag-of-Word，向量长度为lexicon长度，基于计数的。

Hinton最开始做的是把document的BOW作为autoencoder的输入，然后经过几层网络压缩到2维（利于平面表示），发现文章分类效果很好。

## Pre-trained DNN

先对DNN某一层使用autoencoder的训练，然后fix这一层的W**作为initialization**，然后之后除了最后一层每一层都通过autoencoder来得到initialization。最后一层random inital，因为其与分类和label有关。最后back propagation来fine-tune一下前几层的维度。

现在的train的各种技术已经很少用pre-train，但是在**大量单语料的情况下，只有少量label data，可以通过autoencoder去学习前面几层的表示，后面就只需要fine-tune最后一层。**

## Denoising autoencoder

输入加噪声，然后通过autoencoder后的结果与noise之前的原输入对比。

## Contractive autoencoder

希望当input变化的时候，minimize其对representation的影响。

## CNN

![unpooling](/img/unpooling.png)
要记住当初是哪一个位置取得的最大值，之后将其恢复到对应位置，其他位置补0。Keras实现的部分是每个东西复制4份。

![deconvolution](/img/deconvolution.png)
**Actually, deconvolution is convolution.**实质上就是pooling之后再利用相反的kernel来做convoluiton，没有差别。也就是所谓的转置什么的。

# Deep Generative Models

**What I cannot create, I do not understand.**

## Pixel RNN

一种按像素/声音采样/视频帧一步一步生成样本的方法。Evaluate时**可以给他一些10个单词开头，然后给5个，然后什么都不给，看性能的变化。**


# Variational Autoencoder

## 台大李宏毅老师

![VAE-1](/img/vae_1.png)

图片右下角应该maxmize。 

与普通的自编码器不同，**VAE在编码过程中增加一些trick，控制分布，迫使encoder得到的表示粗略服从于标准正态分布**，这样利用decoder做generation的时，随机生成一个标准正态分布的向量就可以开始了。

### Intuitive Reason

![VAE-2](/img/vae_2.png)

认为上面的m code是原来的representation，下面的运算是加入一个噪声，c就是code with noise。这里的sigma为了生成一个noise，表征这个noise的方差大小，因为方差要是正的所以取一个exp(sigma)作为variance，e是从normal分布里面取得，称exp(sigma)以后改变了方差，还是一个分布。

**The variance of noise is automatically learned.**如果只用reconstruction error的话，机器会认为variance越小越好，越利于重构，所以我们要加入新的目标函数：

$$
\sum _ { i = 1 } ^ { 3 } \left( \exp \left( \sigma _ { i } \right) - \left( 1 + \sigma _ { i } \right) + \left( m _ { i } \right) ^ { 2 } \right)
$$

以这个作为Loss，前两项最小值sigma取0，此时variance取1，这样保证了variance不能太小。第三项是L2 regularization，使结果sparse，不会over-fitting。

### Gaussian Mixture Model

想Generative一张图片的话，只要有了所有的「图片表示空间」的点的「概率分布」，我们只要sample那些概率高的点就可以reconstruct出很真实的图片了。

GMM是很多Gaussian（正态分布）按权重叠加起来，就可以得到很复杂的模型，在sample时先用multinomial选出要从哪一个小Gaussian中sample，然后再从这个Gaussian里面sample出一个x。于是有：

$$
P(x) = \sum_{m}P(m)P(x|m)
$$


但是这样只有有限个Gaussian，我们希望有无限种可能。改为，例如，从standard normal distribution（也可以是其他分布，但是即使使用简单的标准正态分布，通过以下算法也可以拟合出超级复杂的P(x)）里面sample一个z，其每一个维度代表了一种属性，然后以z作为输入，**通过一个NN得到mean(z)和variance(z)**，作为新Gaussian的均值和方差，然后从中取x。这样相当于Infinite Gaussian无限个高斯函数，而原来的Gaussian Mixture只能有有限个。此时有：

$$
P(x) = \int_{z}P(z)P(x|z)dz
$$


### KL divergence

作用是**衡量两种分布的相似度**

### 生成阶段

可以固定住n-2个维度，只变换另外两个维度，观察他们的含义。有一篇关于VAE生成Sentences的[文章](https://arxiv.org/abs/1511.06349)。

### Conditional VAE

捕捉输入的特征，生成有类似特征的其他样本。[论文](https://arxiv.org/pdf/1406.5298v2.pdf)

### 存在的问题

VAE是产生一张image与输入越接近越好，它学会怎么产生和database很像的图片，不会想真的image是什么样。只会模仿，没有办法产生新的image。


## Standford CS231n


模型就是定下了计算方式，然后有一组参数，通过数据计算来估计这组参数的值。

$$
P(x) = \int_{z}P(z)P(x|z)dz
$$

首先假设没有encoder，直接从decoder开始，P(z)是个简单的Gaussian，因为从因变量重建输入是复杂的函数，不可以直接指定了，所以使用NN来表示P(x|z)。

要训练上述模型，maximize likelihood of training data，所以就要在z的取值范围上积分，得到生成训练样本X的概率（或者二者的差别），反向传播。但是**对z积分是intractable的**

定义一个Q(z|x)，来逼近真实的后验分布P(z|x)，得到数据likelyhood的下界，且是容易解的，可优化的。

encoder又可以称为**recognition/inference**，decoder叫**generation**。

这里将右侧两项认为是log(P(x))的lower bound，是可以优化的，把左侧第二项认为是一个大于等于零。我们只优化lower bound。Lower bound是ELBO。

![](/img/stanford_vae.png)

总结，使用了随机分布和采样的思想，积分不好推，我们只使用Lower bound。

## Ali Ghodsi

一个普通的单层autoencoder，如果没有激活，没有非线性层，x->h->x，这就类似于一个PCA。PCA是对于d维的x，先矩阵U^T变换到p维度上的y，然后再使用U将y重新回到x。这里U和U^T用的transpose。PCA中限制U为正交阵。

变分法： 图模型中有些变量的局部条件分布可能非常复杂，或其积分无法计算。变方法（Variational Method）是引入一个变分分布（通常是比较简单的分布）来近似这些条件概率，然后通过迭代的方法进行计算。首先是更新变分分布的参数来最小化变分分布和真实分布的差异（比如交叉熵或KL距离），然后再根据变分分布来进行推断。

对于VAE来讲，q(z)是引入的，p(z|x)是我们想拟合的，最小化这两个的KL距离，得到从样本X来推测隐变量z的方法。

q(z)被称为变分分布。

# CNN-DCNN获取句子表征

常用模型在Decoder阶段都是一个一个输出的，这个模型想一次性输出全部句子。通过CNN和DCNN。

evaluate，文本分类，中间。

## encoder

句子都补成60维，embedding_size 300。把输入矩阵卷积，卷积核心300（embeddingsize）x5，300个，