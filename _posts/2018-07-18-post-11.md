---

layout: post
title: Sequence Models and LSTM in Part-of-Speech Tagging 词性标注
date: 2018-07-18 09:28:09
tags: [NLP, LSTM]
categories: [NLP, LSTM]

---

继续官方tutorials系列。

# 概念

特别注意LSTM输出维度的意义。输入为3D Tensor。例如，每句话有5个单词，每个词向量维度为10，batch-size即句子数为3，则LSTM的输入维度应该是(5, 3, 10)。如果认为mini-batch大小为1的话，这个维度跟embedding的维度记法是相同的，每行一个词，列数为一个词的维度。

hidden_state就是output，从cell_state中来。

# Quick Example

```python
lstm = nn.LSTM(3, 3)
inputs = [torch.randn(1, 3) for _ in range(5)]
# initialize the hidden state
hidden = (torch.randn(1, 1, 3),
		  torch.randn(1, 1, 3))
# 方法一：逐词输入
for i in inputs:
	out, hidden = lstm(i.view(1, 1, -1), hidden)

#方法二：Vectorize 一次性
inputs = torch.cat(inputs).view(len(inputs), 1, -1)
hidden = (torch.rand(1, 1, 3), torch.randn(1, 1, 3))
out, hidden = lstm(inputs, hidden)
```

1. `nn.LSTM(input_dim, hidden_dim, num_layers)`，层数默认为1，可以省略。
2. LSTM的output形状与层数无关，与输入序列长度有关。层数是以上一层输出作为输入的stacked堆叠。
3. LSTM的输入为`(input, (h_0, c_0))`，若没给出h_0和c_0，则默认初始化为0，注意要给就全给，要不就全不给。此处的hidden是形如(h_0, c_0)的包含隐状态和细胞状态的综合输入，其中h_0和c_0的维度与lstm输出维度类似，第二维是batch_size，第三维为隐藏层的size。**h_i和c_i是同形的，这一点从LSTM工作原理的门操作也可以知道。**
4. 最完整的输出应该为**(outputs, (hidden, cell))**，其中后一个tuple为最后一个时刻的隐状态和细胞状态。取出的方法有`out, hidden = lstm(inputs, hidden)`，这样得到的hidden是一个(h_n, c_n)的tuple；或者`out, (hidden, cell) = lstm(inputs, hidden)`，这样unpack一下，得到三个tensor。
5. `torch.cat(seq, dim)`按dim制定的维度连接几个tensor。

# LSTM for Part-of-Speech Tagging

## 概念和方法

POS Tagging即词性标注，为句子中的每个词分类。方法为将长度为W的句子通过一个LSTM网络，得到长度为W的输出向量，再经过FC+log_softmax层，取最大的一个作为标签。

## 数据预处理
从语料中建立词典，方便后面词向量的训练；同时建立标签的字典，使其数字化。
```python
def prepare_sequence(seq, to_ix):
	idxs = [to_ix[word] for word in seq]
	return torch.LongTensor(idxs)

training_data = [
    ("The dog ate the apple".split(), ["DET", "NN", "V", "DET", "NN"]),
    ("Everybody read that book".split(), ["NN", "V", "DET", "NN"])
]

word_to_ix = {}
for sent, tags in training_data:
	for word in sent:
		if word not in word_to_ix:
			word_to_ix[word] = len(word_to_ix)
print(word_to_ix)
tag_to_ix = {"DET": 0, "NN": 1, "V": 2}

EMBEDDING_DIM = 6
HIDDEN_DIM = 6
```

这里将词嵌入和隐层的维度设置的小一些，以便于观察效果。

## 模型定义

```python
class LSTMTagger(nn.Module):
	def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):
		super(LSTMTagger, self).__init__()
		self.hidden_dim = hidden_dim
		# 词嵌入
		self.word_embedding = nn.Embedding(vocab_size, embedding_dim)
		# 词向量通过LSTM产生隐状态
		self.lstm = nn.LSTM(embedding_dim, hidden_dim)
		# 一个FC层，将隐状态映射到tag空间
		self.hidden2tag = nn.Linear(hidden_dim, tagset_size)
		self.hidden = self.init_hidden()

	def init_hidden(self):
		return (torch.zeros(1, 1, self.hidden_dim),
				torch.zeros(1, 1, self.hidden_dim))

	def forward(self, sentence):
		embeds = self.word_embedding(sentence)
		lstm_out, self.hidden = self.lstm(embeds.view(len(sentence), 1, -1), self.hidden)
		tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))
		tag_socres = F.log_softmax(tag_space, dim=1)
		return tag_socres
```

## 训练过程
```python
# 实例化模型，损失函数和优化器
model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))
loss_function = nn.NLLLoss()
optimizer = optim.SGD(model.parameters(), lr=0.1)

for epoch in range(300):
	for sentence, tags in training_data:
		model.zero_grad()
		model.hidden = model.init_hidden()

		sentence_in = prepare_sequence(sentence, word_to_ix)
		targets = prepare_sequence(tag, tag_to_ix)

		tag_socres = model(sentence_in)

		loss = loss_function(tag_socres, targets)
		loss.backward()
		optimizer.step()
```

## 测试

```python
with torch.no_grad():
	inputs = prepare_sequence(training_data[0][0], word_to_ix)
	tag_socres = model(inputs)
	print(tag_socres)
```

## 总结
1. LSTM隐层需要初始化，该tutorial作者更喜欢将(h_0, c_0)联合初始化。
2. LSTM层输入必须3D，这里在中间增加一个表示batch_size的维度1，LSTM可以一次喂入一个句子的所有词向量，一行一个词；输出lstm_out也是三维的，中间一个维度同样表示batch_size，在喂入fc层的时候注意调整维度为二维。hidden2tag层是一个普通FC层，输入是表示隐层状态的向量，要求是一个二维的向量，每一行表示一个样本，在这里具体就是每一步的隐层状态；输出也是每行一个样本，共有tag_size列。log_softmax的输入可以是二维的，也是每行一个样本，`dim=1`表示按行来进行softmax的归一化，得到概率的形式。
2. 网络的走向是：源句子 ->(经过字典)-> 词汇索引 ->(作为embedding的输入)-> 词向量 ->(经过LSTM)-> 得到输出隐状态 ->(经过FC层)-> 映射到tag_set的分布向量 —>(softmax)-> 得到预测标签
4. 除了训练阶段之外，都用`torch.no_grad()`。
5. 训练集的格式一般为**[(data), tag]**的形式！
6. 开始训练时，除了网络的梯度归零之外，**LSTM的隐状态也要重新初始化**，这也是为什么单独把隐状态初始化写为一个函数。