---

layout: post
title: 《深度学习框架：PyTorch》学习笔记（5）常用工具
date: 2018-07-10 09:28:09
tags: [PyTorch]
categories: [PyTorch]

---

# 数据加载

数据加载相关的包都在`torch.utils`中，需要`from torch.utils import data`，再使用data中的`Dataset`和`Dataloader`等方法。

PyTorch中，通过自定义的**数据集对象**来封装自己的数据集，需要**继承Dataset类**，并实现两个Python魔方方法：`__getitem__(self, index)`和`__len__(self)`分别实现`obj[index]`和`len[obj]`。自定义Dataset类之后再使用**Dataloader**来实现数据的并行加载。

对于图像的处理，面对文件夹下的很多图像，如何将其读入PyTorch中呢：
```python
from PIL import Image
import numpy as np
pil_img = Image.open(img_path)
array = np.asarray(pil_img)
data = t.from_numpy(array)
```

流程为：PIL.Image打开图片 -> 保存为pil_img -> 转换为np格式 -> 转换为tensor格式。

在实例化自定义的dataset之后，使用dataloader来加载batch数据，一般方法为：
```python
train_dataloader = DataLoader(train_data, batch_size,
                    shuffle=True, num_workers=num_workers)
for batch_datas, batch_labels in train_dataloader:
	train()
```

# 可视化工具
## Tensorboard

这里用的是tensorboard_logger来记录损失函数，首先启动Tensorboard，指定路径，绑定端口：
```shell
tensorboard --logdir <dir> --port <port>
```

使用时，首先构建logger对象，再用这个logger对象来记录数据：
```python
from tensorboard_logger import Logger
logger = Logger(logdir = 'dir', flush_secs = 2)
for ii in range(100):
	logger.log_value('loss', 10--ii**0.5, step = ii)
```
## Visdom

Facebook为PyTorch开发的可视化工具，非常轻量级。
## Tensorboard-X

针对PyTorch开发的，比tensorboard_logger功能强大，封装了大部分Tensorboard的借口。
# GPU加速

Tensor，Variable和nn.Module（包括所有layer，loss和Sequential）数据结构都包含CPU和GPU两个版本，它们都有一个`.cuda()`方法，调用这个方法就可以把所有数据转移到GPU。

除了`.cuda()`方法外，还有`torch.cuda.device(n)`来指定使用GPU n，使用方法为：
```python
with torch.cuda.device(1):
	...
```

一般情况下，调用默认参数的`tensor.cuda()`方法会将数据保存到第一块GPU上，等价于`tensor.cuda(0)`，这样要更改很麻烦。一种解决的方法是先调用`torch.set_device(1)`指定第二块GPU，这样后续的默认操作都会在第二块GPU操作。

还有一种常用的方法是在命令行中，设置环境变量`CUDA_VISIBLE_DEVICES = 0, 2, 3`。这里的原理是设置逻辑GPU与物理GPU的对应，例如上条语句之后，那1，3，4号GPU就是逻辑1，2，3号GPU，这时我执行`t.cuda(1)`，程序会将t的数据保存到第2块逻辑GPU上，也就是物理上的GPU 3。

分布训练和并行训练的区别：分布训练指不同服务器的不同GPU上同时训练，一般人接触不到。并行指一机多卡的训练。

# 持久化

模型、数据和优化器都可以持久化到硬盘，并能通过相应的方法再加载到内存中。通过`t.save(obj, file_name)`和`t.load(file_name)`即可：
```python
a = t.tensor(3, 4)
if t.cuda.is_avialable():
	a = a.cuda(1)
	t.save(a, 'a.pth')
	b = t.load('a.pth')
```
模型的保存：
```python
from torchvision.models import AlexNet
model = AlexNet()
t.save(mode.state_dict(), 'net.pth')
model.load_state_dict(t.load('net.pth'))
```
Optimizer的保存和加载方法与Model的相同，都是调用自身的`.state_dict()方法`返回所有参数的字典，加载时调用自身的`.load_state_dict(t.load('net.pth'))`。