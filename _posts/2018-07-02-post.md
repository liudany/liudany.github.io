---

layout: post
title: 《深度学习框架：PyTorch》学习笔记（1）快速入门
date: 2018-07-02 09:28:09
tags: [PyTorch]
categories: [PyTorch]

---
# 写在前面
折腾了一学期各种框架和模型，TensorFLow的静态图方式用了很久都不适应。相比之下对我来说，PyTorch的可写可读性都要强出很多，而且越来越多的优秀项目使用PyTorch写的了。看这本书的最终目标是读懂StarGAN和FairSeq！

# IPython & Jupyter Notebook
因为我们的服务器和很多机器用的一个公网地址，所以想配置Jupyter服务器还要去服务器在的实验室配置一下路由器的端口转发，有时间去搞一下，现在自己电脑上学着。



# Tensor
Tensor就是可以使用GPU加速的高维数组。Tensor和numpy的数组之间可以相互转换，且共享内存，共同变化。
```python
a = torch.ones(5)
b = a.numpy()
c = torch.from_numpy(b)
```
# Autograd & Variable
Variable封装了Tensor，可以分为`data + grad + grad_fn`三部分，并增加了`.backward`反向传播的功能（认为Tensor和Variable是`requires_grad`属性不同的同一类变量即可）。调用Variable中Tensor数据的方法为`Variable.data`，调用Variable梯度数据的方法为`Variable.grad.data`，也就是说`.grad`属性其实也是一个Variable变量。举例来说，进行梯度下降的算法可以表示为：
```python
w.data.sub_(w.grad.data * learning_rate)
```

在反向传播时会出现两种错误，第一个，如果没给参与运算的Variable指定`requires_grad`属性为真的话：
```python
from torch.autograd import Variable
x = Variable(t.ones(3, 5), requires_grad = False)
y = x.sum()
y.backward()
x.grad
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
```

某些运算不能`直接`反向传播，比如余弦：
```python
x = Variable(t.ones(3, 5), requires_grad = False)
y = t.cos(x)
y.backward()
x.grad
RuntimeError: grad can be implicitly created only for scalar outputs
```
7/4：这里不是因为余弦的问题。y是一个tensor，不可以隐式的调用.backward()方法，只有标量（例如大部分情况下的loss）可以这样使用。
在对矢量反向传播的场合必须添加参数`v.backward(grad_variables)`，将第一层的导数添加进来。

# nn & 实现CIFAR-10分类
CIFAR-10是一个常用的10类别3通道32x32彩色图像物体识别的小数据集，用个例子说明下PyTorch搭网络的一般流程。

## 数据预加载和预处理
```python
import torchvision as tv
import torchvision.transforms as transforms
from torchvision.transforms import ToPILImage
show = ToPILImage() #实例化

transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                             ])
```

1. torchvision是专门用于图像的包，其中tv.datasets中包含了常见的各种图像数据（MNIST，CIFAR-10，Imagenet等），可返回一个Dataset对象。Dataset对象可以使用索引的方式访问，方法为`(data, label) = dataset[10]`，注意标签的序列化和图像数据的tensor形式。
2. tv.transform中的ToPILImage如名字，形如(C, H, W)的Tensor数据转化为PIL(Python Image Library)的数据，方便用show方法显示图片。
3. ToPILImage为一个class，`show = IoPILImage()`实例化。
4. `transforms.Compose()`将一系列的transform动作chained together，整合为一个transform流程。上面例子中先转为Tensor，再标准化，其中第一个(0.5, 0.5, 0.5)为每个通道的均值，第二个括号为每个通道的标准差。

```python
trainset = tv.datasets.CIFAR10(
                    root='/home/cy/tmp/data/', 
                    train=True, 
                    download=True,
                    transform=transform)

trainloader = t.utils.data.DataLoader(
                    trainset, 
                    batch_size=4,
                    shuffle=True, 
                    num_workers=2)

testset = tv.datasets.CIFAR10(
                    '/home/cy/tmp/data/',
                    train=False, 
                    download=True, 
                    transform=transform)

testloader = t.utils.data.DataLoader(
                    testset,
                    batch_size=4, 
                    shuffle=False,
                    num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```
1. trainset和testset都是dataset对象，可以通过下标来索引，数据为(data, label)形式。
2. torch.utils是一个工具包，其中的.data.Dataloader用于加载数据集，第一个参数为刚才生成的dataset对象，返回一个可用于迭代的加载器。例如可用`iter()`函数生成迭代器后`.next()`方法查看下一个元素。其元素格式为`(data[batch_size], label[batch_size])`，以batch为单位。

```python
dataiter = iter(trainloader)
images, labels = dataiter.next()
print(' '.join('%11s'%classes[labels[j]] for j in range(4)))
show(tv.utils.make_grid((images+1)/2)).resize((400,100))
```
1. 用`iter()`函数生成了迭代器，并用`.next()`方法一次性获取上面设置的`batch_size`个数据与标签。
2. torchvision包的utils工具包中`make_grid()`函数为一系列相同大小Tensor格式图像(B x C x H x W)画边框。

## 定义网络

实现LeNet网络。
```python
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5) 
        self.conv2 = nn.Conv2d(6, 16, 5)  
        self.fc1   = nn.Linear(16*5*5, 120)  
        self.fc2   = nn.Linear(120, 84)
        self.fc3   = nn.Linear(84, 10)

    def forward(self, x): 
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) 
        x = F.max_pool2d(F.relu(self.conv2(x)), 2) 
        x = x.view(x.size()[0], -1) 
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)        
        return x


net = Net()
print(net)
```
1. PyTorch在定义网络时，需要继承`nn.Moudle`模块，并在构造函数中执行父类的构造函数。代码中的`super()`函数返回父类。
2. 尽量把网络中具有可学习参数的层（卷积层Conv2d，全连接层Linear）放在构造函数`__init__`中。
3. 实现网络类的`forward()`函数，进行前向传播。此处流程为 卷积->ReLU->最大池化->卷积->ReLU->最大池化->全连接层->ReLU->全连接层->ReLU->全连接层。
4. `x.view(x.sizer()[0], -1)`将x reshape为括号中的形状。其中`-1`为自适应，保持变化前后元素相等。

## 定义损失函数和优化器

```python
from torch import optim
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```
1. 一般用criterion变量表示损失函数，评价标准，对的。
2. 将Net实例化为net后，`net.parameters()`可以返回所有的可学习参数，`net.name_parameters()`可以返回参数名称和参数。
3. 这是将两个类实现为各自的实例。

## 训练网络
```python
t.set_num_threads(8)
for epoch in range(2):  
    
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = Variable(inputs), Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()   
        
        optimizer.step()
        
        running_loss += loss.data[0]
        if i % 2000 == 1999:
            print('[%d, %5d] loss: %.3f' \
                  % (epoch+1, i+1, running_loss / 2000))
            running_loss = 0.0
print('Finished Training')
```
1. `enumerate()`函数将可遍历的对象组合为索引序列，常用于for循环当中：`for i, data in enumerate(seq, start = 1)`。
2. 这里的data是trainloader中的一个batch，并不是某一个样本，格式为`(data[], label[])`个数为`batch_size`个。
3. `optimizer.zero_grad()`与`net.zero_grad()`作用相同，清空梯度值。
4. `out = net(inputs)`可以实现前向传播，注意输入必须转换为Variable才会有自动求导功能！
5. 由损失函数开始向后铺开反向传播。
6. `optimizer.step()`可以更新参数，其中`optimizer`为刚才创建的优化器对象，其中已经指定了所有的可学习参数。
7. `running_loss += loss.data[0]`，上一步的`loss`计算出以后是Variable变量，`loss.data`是一个Tensor，而`loss.data[0]`是一个Python数字。
8. 每2000步输出一个loss的均值，然后清零。

## 在测试集某batch上的效果
```python
dataiter = iter(testloader)
data, label = dataiter.next()
print('实际的label：', ' '.join('%08s' %classes[labels[j]] for j in range(4)))
outputs = net(Variable(data))
_, predicted = t.max(outputs.data, 1)
```

1. `tensor.max(outputs.data, 1)`：首先outputs是一个Variable，取他的Tensor部分。若为`max(outputs)`则只返回一个最大的数字，后面加上参数`1`则取每行的参数最大值，这个函数返回两个值，第一个是每行的最大值组成的tensor，第二个是每行的最大值所在位置的索引组成的tensor。我们往往使用第二个返回值。
2. labels是一个generator变量，这里的输出方式留个坑，后面填。

## 测试集上的总效果
```python
correct = 0
total = 0
for data in testloader:
    images, labels = data
    outputs = net(Variable(images))
    _, predicted = t.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum()
print('10000张测试图片中的准确率为：%d %%' % (100 * correct / total))
```
1. testloader中每一个元素为一个形如`(data[batch_size], label[batch_size])`的元组，凡是与`dataloader`相关的都是以batch为单位。
2. `(predicted == labels)`返回一个形如`[0, 1, 1, 0]`的Tensor，置位处为判断正确的样本。