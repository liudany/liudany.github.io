I"ª"<p>First of all, this paper is not about generative model. Jump out of VAE.</p>

<h2 id="multi-aspect-task">Multi-aspect Task</h2>

<p>Usually a document consists of several sentences describing one or more aspects. Document-level multi-aspect sentiment classification(DMSC) aims to predict the sentiment polarity for each aspect.</p>

<p>In this paper, authors introduce a weakly supervised approach to dealing with insufficient labeled data. Opinion-target word pairs of different aspects are extracted from document.</p>

<h2 id="é’ˆå¯¹çš„é—®é¢˜">é’ˆå¯¹çš„é—®é¢˜</h2>

<p>There is not sufficient labeled data in aspect-level annotations, making unsupervised/weakly-supervised necessary.</p>

<h2 id="ç°å­˜çš„æ–¹æ³•">ç°å­˜çš„æ–¹æ³•</h2>

<ol>
  <li>Existing weakly supervised methods use <strong>overall polarities(a weighted sum of all aspect polarities)</strong> instead of aspect polarities as â€œsupervisionâ€, which could not estimate a paticular rare aspect.</li>
  <li>These approaches assume the document is a BOW, which neglects the order of words.</li>
</ol>

<h2 id="æ”¹è¿›çš„æ€è·¯">æ”¹è¿›çš„æ€è·¯</h2>

<ol>
  <li>Use target-opinion word paris as â€œsupervisionâ€. For example â€œbed-spaciousâ€, the polarity tends to be positive for aspect â€œbedâ€. Introduce the sentiment polarity as the latent variable.</li>
  <li>Use a deep neural network architecture to extract document representation instead of BOW.</li>
</ol>

<h2 id="model">Model</h2>

<p>The ultimate goal is to learn a classifier that predicts the sentiment polarity of multi-aspects given a document(which is now a sub-task in the experiment).</p>

<p>Authors achieve this goal by accomplishing another relevant objective: to predict an opinion word given a target word. Specifically, the opinion word prediction task is decomposed into 2 parts:</p>

<ul>
  <li>Predict the sentiment polarity of a certain aspect given a document</li>
  <li>Predict the opinion word based on the target word and the predicted sentiment polarity in first step.</li>
</ul>

<blockquote>
  <p>By introducing a latent variable, i.e., the sentiment polarity of an aspect, to the opinion word prediction objective, we can inject the polarity classification goal (the first sub-task) into the objective via the variational lower bound which also incorporates the second sub-task.</p>
</blockquote>

<p>The above words indicate that predicting opinion words is not the primary objective, but we could learn a good polarity classifier through the two-stage training method. Because the second task relies on the polarity predicted in the first task, requiring it to be accurate.</p>

<p>âš ï¸The reason authors regard the ultimate goal(polarity) as a latent variable is that the supervised (document-polarity) data is insufficient. But we could instead extract sufficient target-opinion words as end-to-end training data, making our polarity classifier as a by-product.</p>

<h3 id="sentiment-polartiy-classifier">Sentiment Polartiy Classifier</h3>

<script type="math/tex; mode=display">q \left( R _ { a } = r _ { a } | \mathbf { x } \right) = \frac { \exp \left( \mathbf { w } _ { r _ { a } } ^ { T } \mathbf { x } \right) } { \sum _ { r _ { a } ^ { \prime } } \exp \left( \mathbf { w } _ { r _ { a } ^ { \prime } } ^ { T } \mathbf { x } \right) }</script>

<h3 id="opinion-word-classifier">Opinion Word Classifier</h3>

<script type="math/tex; mode=display">p \left( w _ { o } | r _ { a } , w _ { t } \right) = \frac { \exp \left( \varphi \left( w _ { o } , w _ { t } , r _ { a } \right) \right) } { \sum _ { w _ { o } ^ { \prime } } \exp \left( \varphi \left( w _ { o } ^ { \prime } , w _ { t } , r _ { a } \right) \right) }</script>

<p>Use the negative sampling technique to <strong>approximate</strong> the opinion word classifier.
<script type="math/tex">\log \sigma \left( \varphi \left( w _ { o } , w _ { t } , r _ { a } \right) \right) + \sum _ { w _ { o } ^ { \prime } \in \mathcal { N } } \log \sigma \left( - \varphi \left( w _ { o } ^ { \prime } , w _ { t } , r _ { a } \right) \right)</script></p>

<h3 id="objective">Objective</h3>

<p>Given the above two classifier, we could derive the objective as follows:</p>

<p><img src="/img/eq1.png" alt="" /></p>

<p>Notice that $r_a$ is the latent variable.</p>

<ol>
  <li>Inject the latent variable into the objective.</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Introduce the training flow(r</td>
          <td>x), combine the sub-models.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Jensenâ€™s Inequation. Note that the term on RHS of line 4 can be regarded as a KL term.</li>
  <li>This transformation can be applied to any KL divergency.</li>
  <li>ra is indepent of wt.</li>
  <li>Assume that the sentiment polarity Ra follows a uniform distribution, which means p(ra) is a constant.</li>
</ol>

<p>The ultimate objective is:
<script type="math/tex">\mathbb { E } _ { q \left( R _ { a } | \mathbf { x } \right) } \left[ \log p \left( w _ { o } | r _ { a } , w _ { t } \right) \right] + H \left( q \left( R _ { a } | \mathbf { x } \right) \right)</script></p>

<h2 id="æ¦‚ç‡å…¬å¼æ¨å¯¼å’Œæ¨¡å‹æ„é€ ä¹‹é—´çš„å…³ç³»">æ¦‚ç‡å…¬å¼æ¨å¯¼å’Œæ¨¡å‹æ„é€ ä¹‹é—´çš„å…³ç³»</h2>

<h3 id="æ¡ä»¶æ¦‚ç‡">æ¡ä»¶æ¦‚ç‡</h3>

<table>
  <tbody>
    <tr>
      <td>æ¡ä»¶æ¦‚ç‡ç”¨çš„æœ€å¤šï¼Œå› ä¸ºä»¥xä¸ºè¾“å…¥çš„ç¥ç»ç½‘ç»œå¯ä»¥çœ‹ä½œP(y</td>
      <td>x)ï¼Œä½†æ˜¯å¦‚ä½•å¾—åˆ°è¿™ä¸ªåˆ†å¸ƒå‘¢ï¼Ÿ</td>
    </tr>
  </tbody>
</table>

<p>å¯¹äº<strong>å‚æ•°åŒ–</strong>çš„åˆ†å¸ƒæ—æˆ‘ä»¬å¯ä»¥é€šè¿‡ç½‘ç»œè¾“å‡ºå¾—åˆ°åˆ†å¸ƒçš„å‚æ•°ä»è€Œæ„é€ è¿™ä¸ªåˆ†å¸ƒã€‚è€Œæœ¬æ–‡ä¸­çš„<strong>ç¦»æ•£åˆ†å¸ƒ</strong>å¯ä»¥ç›´æ¥é€šè¿‡ç½‘ç»œè¾“å‡º+softmaxå¾—åˆ°ä¸€ä¸ªç¦»æ•£åˆ†å¸ƒã€‚ç¦»æ•£åˆ†å¸ƒä¹Ÿæ˜¯å‚æ•°åŒ–çš„åˆ†å¸ƒã€‚</p>

<h3 id="æœŸæœ›">æœŸæœ›</h3>

<p>æœ‰äº†åˆ†å¸ƒï¼Œå¯è¿›è¡Œé‡‡æ ·æ¥è¿‘ä¼¼å¾—åˆ°æœŸæœ›ã€‚ä½†æ³¨æ„é‡‡æ ·æ˜¯ä¸å¯BPçš„ï¼Œæ‰€ä»¥é’ˆå¯¹é«˜æ–¯åˆ†å¸ƒï¼ˆæˆ–å…¶ä»–ç”±å‡å€¼å’Œæ–¹å·®ä¸ºå‚æ•°çš„å‚æ•°åŒ–åˆ†å¸ƒæ—ï¼‰æœ‰reparameterizationçš„æ–¹æ³•æ¥æ”¯æŒBPã€‚</p>

<p>ä½†æ˜¯ä¸æ˜¯æ‰€æœ‰çš„æœŸæœ›éƒ½æ˜¯é€šè¿‡é‡‡æ ·æ¥æ¨¡æ‹Ÿçš„ã€‚æœ¬æ–‡ä¸­raæœä»ç®€å•çš„ä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥ç²¾ç¡®æ±‚è§£è¿™ä¸ªæœŸæœ›ã€‚</p>

<h3 id="æŸå¤±å’Œæ¨¡å‹">æŸå¤±å’Œæ¨¡å‹</h3>

<table>
  <tbody>
    <tr>
      <td>VAEä¸­ç”±P(X</td>
      <td>z)å¾—åˆ°äº†æŸå¤±ä¸­çš„é‡æ„é¡¹ï¼Œè¿™æ˜¯å› ä¸ºæ¨å¯¼çš„å…¬å¼é‡Œæœ‰logP(X</td>
      <td>z)è¿™ä¸€é¡¹ï¼Œè€ŒPåˆšå¥½åˆæ˜¯é«˜æ–¯åˆ†å¸ƒï¼Œæ‰€ä»¥æŸå¤±çš„æœ€ç»ˆåŒ–ç®€ä¸ºå‡å€¼ï¼ˆç½‘ç»œè¾“å‡ºï¼‰å’ŒçœŸå®æ ·æœ¬Xä¹‹é—´çš„æ¬§æ‹‰è·ç¦»çš„å½¢å¼ã€‚è¿™ä¸ªçš„æˆç«‹å®Œå…¨å–å†³äºç”Ÿæˆæ¨¡å‹ç¬¦åˆé«˜æ–¯åˆ†å¸ƒè¿™ä¸ªå‡è®¾ã€‚æˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ ¹æ®æ ·æœ¬å¾—åˆ°zåˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®ï¼Œé€šè¿‡é‡‡æ ·æ³•æ¥æ±‚è§£å‡å€¼ï¼Œæœ€ç»ˆæ ¹æ®ç”Ÿæˆæ¨¡å‹å¾—åˆ°çš„å‡å€¼ï¼Œå³ç½‘ç»œè¾“å‡ºæ¥ç®—å‡ºè¯¯å·®ï¼Œåå‘ä¼ æ’­ã€‚</td>
    </tr>
  </tbody>
</table>

<p>æœ¬æ–‡ä¸­å¹¶æ²¡æœ‰é«˜æ–¯åˆ†å¸ƒçš„å‡è®¾ï¼Œä½†Polarityçš„åˆ†å¸ƒæ˜¯ä¸€ä¸ªä¼¯åŠªåˆ©äºŒé¡¹åˆ†å¸ƒï¼Œä¹Ÿå±äºå‚æ•°åŒ–åˆ†å¸ƒï¼Œæ‰€ä»¥ä½¿ç”¨ç½‘ç»œ+softmaxæ¨¡æ‹Ÿå‡ºraçš„çœŸå®åˆ†å¸ƒã€‚ç”±äºæ˜¯ç¦»æ•£çš„ï¼ŒæœŸæœ›ä¹Ÿå¯ä»¥ç”¨ç´¯åŠ çš„å½¢å¼ç®€å•æ±‚å‡ºï¼Œopinion word predictionæ¨¡å‹ä¸­woç¬¦åˆçš„åˆ†å¸ƒä¹Ÿæ˜¯ä¸€ä¸ªåœ¨è¯è¡¨ä¸Šçš„ç¦»æ•£åˆ†å¸ƒï¼Œå¯ç›´æ¥æ±‚å‡ºæ¦‚ç‡å€¼ã€‚</p>

<p>intracbleçš„æ„æ€æ˜¯è¡¨è¾¾å¼æœªçŸ¥ï¼Œç¨‹åºé‡Œå†™ä¸å‡ºæ¥ã€‚</p>

<table>
  <tbody>
    <tr>
      <td>æ‰€ä»¥ä»æˆ‘ä»¬æƒ³è¦ä¼˜åŒ–çš„ç›®æ ‡å…¥æ‰‹ï¼ŒVAEä¸­æƒ³æœ€å¤§åŒ–ç§¯åˆ†P(X</td>
      <td>z)P(z)ï¼Œç„¶åç»è¿‡ä¸€ç³»åˆ—çš„åŒ–ç®€ï¼Œè¿‘ä¼¼ï¼Œå¾—åˆ°äº†æœ€ç»ˆçš„ELBOï¼Œæˆ‘ä»¬æ ¹æ®ELBOä¸­çš„æ¯ä¸€é¡¹ï¼Œè®¾è®¡æ¨¡å‹ä»¥æ±‚è§£è¿™ä¸ªELBOï¼Œæœ€åä¼˜åŒ–æ¨¡å‹å°±æ˜¯è®©ELBOå˜å¤§ã€‚ä»æŸå¤±ä¸­çœ‹å‡ºæ¨¡å‹åº”è¯¥æ€ä¹ˆæ­ã€‚</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>æœ¬æ–‡ä¹Ÿæ˜¯ï¼Œä»æŸå¤±ä¸­çœ‹å‡ºäº†å…ˆè¦ä»xä¸­å¾—åˆ°raï¼Œå†æ ¹æ®raå’Œwté¢„æµ‹woï¼Œå†åŠ ä¸Šä¸ªç†µã€‚æ‰€ä»¥æ¨¡å‹çš„æ­å»ºä¹Ÿæ˜¯è¿™æ ·çš„ã€‚ä½†æ˜¯ä¸ºä»€ä¹ˆæŸå¤±ä¼šä»logp(w0</td>
      <td>wt)å¾€è¿™ä¸ªæ–¹å‘åŒ–ç®€å‘¢ï¼Ÿä¸ºä»€ä¹ˆæ’å…¥raç­‰ï¼Œè¿™æ˜¯æœ€åˆçš„æƒ³è¦åˆ©ç”¨å¼±ç›‘ç£çš„æƒ³æ³•å¾—æ¥çš„ï¼Œæ‰€ä»¥æ€»ä½“æ€è·¯ï¼š</td>
    </tr>
  </tbody>
</table>

<ol>
  <li>æœ‰äº†æƒ³æ³•ï¼Œä»åŸç†ä¸Šæƒ³æ€ä¹ˆæ­å»ºè¿™ä¸ªæ¨¡å‹ã€‚</li>
  <li>ä»æœ€åˆçš„æŸå¤±å…¥æ‰‹ï¼Œå¼•å…¥æˆ‘ä»¬æƒ³è¦å¼•å…¥çš„ä¸œè¥¿ï¼Œä¾‹å¦‚raï¼Œxç­‰ã€‚</li>
  <li>åŒ–ç®€æŸå¤±ï¼Œæ‰¾åˆ°å¦‚ä½•ä½¿ç”¨æ–°å¼•å…¥çš„ä¸€ç³»åˆ—å‚æ•°ï¼Œå»å®Œæˆæœ€åˆæŸå¤±çš„ä¼˜åŒ–ã€‚</li>
</ol>

<h2 id="é—®é¢˜">é—®é¢˜</h2>

<p>æ¯ä¸€ä¸ªæ¦‚ç‡q p éƒ½ä¼šç”¨ç½‘ç»œ/æ–¹æ³•ï¼ˆsoftmaxï¼‰æ„é€ å‡ºæ¥ã€‚</p>

<p>ä¸»è¦æ€è·¯æ˜¯æ’å…¥ä¸€ä¸ªä¸­é—´å˜é‡ï¼Œåšéšå˜é‡ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥ç§°ä¸ºå˜åˆ†ã€‚</p>

<h2 id="æƒ³æ³•">æƒ³æ³•</h2>

<ol>
  <li>softmaxç±»å‹çš„å…¬å¼ï¼Œåˆ†æ¯éå†å˜é‡ï¼Œæ‰¾æœ€å¥½çš„</li>
  <li>è´Ÿé‡‡æ ·çš„è¿‘ä¼¼æ–¹æ³•</li>
  <li>labeledæ ·æœ¬ä¸è¶³æ—¶ï¼Œä»¥labelä¸ºéšå˜é‡ã€‚</li>
  <li>vaeçš„jensenæ€ä¹ˆç”¨çš„</li>
  <li>è¿™ä¸æ˜¯ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Œè€Œæ˜¯ä¸€ç§variationalçš„æ–¹æ³•</li>
</ol>
:ET