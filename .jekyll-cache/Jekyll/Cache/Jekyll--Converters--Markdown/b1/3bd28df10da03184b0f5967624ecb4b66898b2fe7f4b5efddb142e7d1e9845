I"<p>7/23</p>

<p>老板让在系统之前加一个目标分类的过程，想通过这个提升一下针对性和准确率。</p>

<p>今天看了下相关方面的综述，日常产生了一种「说不定能在这个领域做出点东西」的错觉。总的来说TextClassification模型分五类：</p>

<ol>
  <li>词嵌入向量化</li>
  <li>基于CNN</li>
  <li>基于RNN及各种变体</li>
  <li>Attention机制</li>
  <li>记忆存储机制</li>
</ol>

<p>可以看到基本的框架结构和其他深度学习方面都是差不多的，好像所有文本任务的发展都是<strong>RNN -&gt; CNN -&gt; Attention</strong>这个方向发展的。</p>

<p>7/24</p>

<p>今天搞搞fastText。</p>

<h1 id="fasttext">fastText</h1>

<h2 id="introduction">Introduction</h2>

<p>Facebook团队做的一个词嵌入和句子分类的工具包。其中有不少看起来很有用的东西：</p>

<ul>
  <li>目前state-of-the-art的英文词向量。</li>
  <li>根据Wiki和爬来的一些数据训练的157种训练好的词向量。</li>
  <li>用于语言识别的模型，和一些有监督任务（指TextClassification）的模型。</li>
</ul>

<p>数据集来自YFCC100M，即Yahoo Flickr Creative Commons 100 Million，还挺唬人的。</p>

<p>总结了一些有用的<a href="https://fasttext.cc/docs/en/cheatsheet.html#content">cheatsheet</a> ，算是快速上手帮助。</p>

<p>这个项目是用PyThon写的，没有使用PyTorch（？）。</p>

<h2 id="安装">安装</h2>

<p>推荐使用make方法来装，也有cmake和Python方法。</p>

<h2 id="使用">使用</h2>

<h3 id="word-vectors">Word Vectors</h3>
<h3 id="text-classification">Text Classification</h3>
<h4 id="语料预处理">语料预处理</h4>

<p>首先下载数据集，官方的tutorial提供了一个关于<a href="https://s3-us-west-1.amazonaws.com/fasttext-vectors/cooking.stackexchange.tar.gz">食物的数据集</a>，需要翻墙下载。其中数据格式形为：</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>__label__sauce __label__cheese How much does potato starch affect a cheese sauce recipe?
__label__food-safety __label__acidity Dangerous pathogens capable of growing in acidic environments
__label__cast-iron __label__stove How do I cover up the white spots on my cast iron stove?
</code></pre></div></div>

<p>每个句子的分类由前面的<code class="highlighter-rouge">__label__xxx</code>来决定，每个句子可以有多个标签，由空格分开。</p>

<p>然后用<code class="highlighter-rouge">tail -n</code>和<code class="highlighter-rouge">head -n</code>命令来划分训练集和测试集：</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head -n 12404 cooking.stackexchange.txt &gt; cooking.train
tail -n 3000 cooking.stackexchange.txt &gt; cooking.train
</code></pre></div></div>

<p><code class="highlighter-rouge">head</code>和<code class="highlighter-rouge">tail</code>命令本身用于查看，<code class="highlighter-rouge">-n</code>参数表示行数，箭头用来将输出生成到文件。</p>

<h4 id="训练和验证">训练和验证</h4>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./fasttext supervised <span class="nt">-input</span> train.txt <span class="nt">-output</span> model
</code></pre></div></div>

<p>其中<code class="highlighter-rouge">train.txt</code>是训练集句子的文件，其中每行是一个句子和它的标签。其中，表示标签的词汇是以字符串<code class="highlighter-rouge">__label__</code>为前缀的。输出为两个文件：<code class="highlighter-rouge">model.bin</code>和<code class="highlighter-rouge">model.vec</code>。</p>

<p>模型训练完毕之后，在测试集上验证准确率：</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./fasttext <span class="nb">test </span>model.bin test.txt k
</code></pre></div></div>

<p>参数<code class="highlighter-rouge">k</code>是可选的，默认为1。</p>

<p>为了获得一个文本对应的k个最可能的标签，使用：</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./fasttext predict model.bin test.txt k
</code></pre></div></div>

<p>或者使用<code class="highlighter-rouge">predict-prob</code>来获得某种标签对应的概率：</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./fasttext predict-prob model.bin test.txt k
</code></pre></div></div>

<p>其中<code class="highlighter-rouge">test.txt</code>中每行为一个待分类的句子。执行上面语句将会在每行输出句子对应的k个最可能的标签。</p>

<p>每次的输出中有<code class="highlighter-rouge">P@1</code>和<code class="highlighter-rouge">R@1</code>，分别为准确率和召回率。准确率是指，模型所预测出的标签中有几个是正确的；召回率是指，原项目的正确标签中有几个被正确预测出来。</p>

<h4 id="提高准确率">提高准确率</h4>

<p>去除标点符号，和进行大小写的转换：</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat cooking.stackexchange.txt | sed -e "s/\([.\!?,'/()]\)/ \1 /g" | tr "[:upper:]" "[:lower:]" &gt; cooking.preprocessed.txt
</code></pre></div></div>
<p>其中，<code class="highlighter-rouge">|</code>分割的命令，将前面的输出作为后面的输入；<code class="highlighter-rouge">sed</code>是强大的文本流处理工具，主要用正则匹配，这里用其曲调标点符号；<code class="highlighter-rouge">tr</code>命令也是用于文本的替换和压缩，这里用其统一大小写；最后再进行训练和验证集合的划分等操作。</p>

<p><code class="highlighter-rouge">-lr</code>和<code class="highlighter-rouge">-epoch</code>参数用于指定学习率和训练的轮数。<code class="highlighter-rouge">-wordNgrams</code>用于使用Ngram方法来训练分类器。<code class="highlighter-rouge">-loss hs</code>开启使用hierarchical softmax，大大提高训练的速度，但是会损失一些准确率。</p>

<h2 id="原理">原理</h2>

<p>是一篇ACL的短文。</p>
:ET